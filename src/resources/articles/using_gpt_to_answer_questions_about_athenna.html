<h1>What is RAG?</h1>
<p class="mt-4 text-justify">
  One of the limitations from Large Language Models (LLM) nowadays is their limited time
  windows of "knowledge", in other words, pure and simple <strong>data</strong>.
  <a target="_blank" class="text-[color:--highlight]" href="https://platform.openai.com/docs/models/gpt-3-5-turbo#gpt-3-5-turbo">The GPT 3.5 Turbo</a>
  training data go up to <strong>Set 2021</strong>, which means that the model doesn't
  know about any important event that comes after that date.
</p>
<p class="mt-4 text-justify">
  And that's what Retrieval-Augmented Generation (RAG) technique tries to solve, it
  provides new sources to get a better output from a Large Language Model (LLM). It
  references an authoritative knowledge base outside of its common training data sources
  before generating a response.
</p>
<p class="mt-4 text-justify">
  Imagine that your company got a very big documentation about infrastructure, architecture,
  processes, etc. With RAG, it's possible to "vectorize" all of that data and use
  text embedding techniques to send the right context to the LLM so he could craft the best
  response possible.
</p>
<h1 class="mt-4">RAG for Athenna Docs</h1>
<p class="mt-4 text-justify">
  Since <a target="_blank" class="text-[color:--highlight]" href="https://athenna.io">Athenna</a>
  has a big documentation, a LLM could be a very good second brain to answer questions quickly
  that the developer might have. The goal was to clone the Athenna documentation repository and create
  data chunks from all <code>.mdx</code> files and insert inside a VectorDB. So when the user
  asks something, we first use a text embedding model to search the most relevant chunks inside our
  vectors to check which one is most probably to contain the right context that the LLM needs to
  answer the question correctly. I created this project using the following tools:
</p>
<ul class="mt-4">
  <li><a target="_blank" class="text-[color:--highlight]" href="https://python.langchain.com/docs/introduction/">LangChain for data processing and chunking</a></li>
  <li><a target="_blank" class="text-[color:--highlight]" href="https://www.trychroma.com/">Chroma as VectorDB</a></li>
  <li><a target="_blank" class="text-[color:--highlight]" href="https://platform.openai.com/docs/models#gpt-3-5-turbo">GPT 3.5 Turbo as LLM</a></li>
  <li><a target="_blank" class="text-[color:--highlight]" href="https://platform.openai.com/docs/models#embeddings">ADA 002 for Text Embedding</a></li>
</ul>
<p class="mt-4 text-justify"></p>
  You can check all the sources in my <strong>Github repository</strong>: <a target="_blank" class="text-[color:--highlight]" href="https://github.com/jlenon7/rag_athenna">jlenon7/rag_athenna</a>
</p>
<h2 class="mt-4">Base RAG</h2>
<p class="mt-4 text-justify">
  The base RAG architecture is the most basic way of implementing this technique:
</p>
<img class="mt-4 block mx-auto w-1/2" src="/public/img/charts/base-rag.png" />
<p class="mt-4 text-justify">
  This architecture is also know as naive RAG, but I don't like this name in particular because depending on
  the use case, the base RAG architecture could already solve the problem. Let's see a response example from
  the LLM by using this architecture:
</p>
<h4 class="mt-4">Question</h4>
<p class="mt-4 text-justify"></p>
  How I could change the routes directory in Athenna Framework?
</p>
<h4 class="mt-4">LLM Answer</h4>
<p class="mt-4 text-justify">
  To change the routes directory in Athenna Framework, you can update the <code>.athennarc.json</code>
  configuration file by modifying the <code>directories</code> property. By default, the routes directory
  is located at <code>"routes": "src/routes"</code>.
</p>
<p class="mt-4 text-justify">
  If you want to change the routes directory to a different location, you can simply
  update the <code>"routes"</code> key within the <code>directories</code> property to
  point to the new directory path. For example, if you want to change the routes directory
  to <code>"app/routes"</code>, you can update the configuration as follows:
</p>
<pre class="code-block">
<code class="my-4 code-block-lines">{
  "directories": {
    "routes": "app/routes"
  }
}</code>
</pre>
<h2>Parent RAG</h2>
<p class="mt-4 text-justify">
  The problem with base RAG architecture is that it could lead to imprecisions due to a larger context.
  If we have larger chunks, lower will be the precision of the LLM and if we have smaller chunks,
  the LLM will have a higher precision, but also less context to craft the response:
</p>
<img class="mt-4 block mx-auto w-1/2" src="/public/img/charts/precision-vs-context.png" />
<p class="mt-4 text-justify">
  To fix this we can use a parent RAG architecture, were we will create larger parent chunks and split
  them in smaller chunks and finally apply the embedding techniques and save in the VectorDB:
</p>
<img class="mt-4 block mx-auto w-1/2" src="/public/img/charts/parent-document-retriever.png" />
<p class="mt-4 text-justify">
  The results are incredible better when compared to the base RAG architecture, the LLM is able to
  provide even more details about how to change the <code>routes</code> directory:
</p>
<h4 class="mt-4">Question</h4>
<p class="mt-4 text-justify"></p>
  How I could change the routes directory in Athenna Framework?
</p>
<h4 class="mt-4">LLM Answer</h4>
<p class="mt-4 text-justify">
  To change the routes directory in Athenna Framework, you can follow these steps:
</p>
<ul class="mt-4">
  <li>Open the <code>.athennarc.json</code> file or the <code>athenna</code> property of your <code>package.json</code>.</li>
  <li>Look for the <code>directories</code> property inside the configuration.</li>
  <li>Add a key-value pair to map the directory base path that you want to use for resolving the routes directory.</li>
</ul>
<p class="mt-4 text-justify">
  For example, if you want to change the routes directory to <code>src/app/routes</code>, you can add the
  following configuration to your <code>.athennarc.json</code> file:
</p>
<pre class="code-block">
<code class="my-4 code-block-lines">{
  "directories": {
    "routes": "src/app/routes"
  }
}</code>
</pre>
<p class="text-justify">
  By doing this, when Athenna resolves the routes directory, it will use the path <code>src/app/routes</code> instead
  of the default path.
</p>
<p class="mt-4 text-justify">
  Remember, Athenna relies on the <code>Path</code> class methods to find files and directories internally, so configuring
  the <code>directories</code> property will help Athenna locate the specified routes directory.
</p>
<h1 class="mt-4">Next Steps</h1>
<p class="mt-4 text-justify">
  Now imagine to have this tool working inside <a target="_blank" class="text-[color:--highlight]" href="https://athenna.io">Athenna Documentation.</a>
  This would be amazing, BUT, LLM's are very expensive even if we use the <a target="_blank" class="text-[color:--highlight]" href="https://ai.meta.com/blog/meta-llama-3/">Llama 3 from Meta</a>,
  the costs to run the model in some cloud is still a thing. So let's wait until we have some free tool to use or at least
  free for open source ðŸ˜….
</p>
